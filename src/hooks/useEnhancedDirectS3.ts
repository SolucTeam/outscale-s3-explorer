/**
 * Hook S3 direct am√©lior√© avec cache intelligent, retry automatique et uploads concurrents
 * Version optimis√©e pour performance et fiabilit√©
 */

import { useState, useCallback, useRef, useEffect } from 'react';
import { proxyS3Service, ProxyS3Response } from '../services/proxyS3Service';
import { useS3Store } from './useS3Store';
import { S3Bucket, S3Object, S3Credentials } from '../types/s3';
import { useToast } from '@/hooks/use-toast';
import { cacheService } from '../services/cacheService';
import { s3LoggingService } from '../services/s3LoggingService';

interface UploadProgress {
  file: string;
  progress: number;
  status: 'pending' | 'uploading' | 'completed' | 'error';
  error?: string;
}

interface RetryConfig {
  maxRetries: number;
  baseDelay: number;
  maxDelay: number;
}

export const useEnhancedDirectS3 = () => {
  const { 
    setBuckets, 
    setObjects, 
    setLoading, 
    setError,
    logout: storeLogout 
  } = useS3Store();
  
  const { toast } = useToast();
  const [initialized, setInitialized] = useState<boolean>(() => proxyS3Service.isInitialized());
  const [uploadProgress, setUploadProgress] = useState<Record<string, UploadProgress>>({});
  const uploadQueueRef = useRef<File[]>([]);
  const activeUploadsRef = useRef<Set<string>>(new Set());
  
  // Sync initialized state with proxy service (important after navigation)
  useEffect(() => {
    if (proxyS3Service.isInitialized() !== initialized) {
      setInitialized(proxyS3Service.isInitialized());
    }
  }, [initialized]);
  
  const retryConfig: RetryConfig = {
    maxRetries: 3,
    baseDelay: 1000,
    maxDelay: 10000
  };

  // Backoff exponentiel pour retry automatique
  const exponentialBackoff = (attempt: number): number => {
    const delay = Math.min(
      retryConfig.baseDelay * Math.pow(2, attempt),
      retryConfig.maxDelay
    );
    return delay + Math.random() * 1000; // Jitter
  };

  // Retry automatique avec backoff
  const withRetry = async <T>(
    operation: () => Promise<ProxyS3Response<T>>,
    context: string
  ): Promise<ProxyS3Response<T>> => {
    let lastError: any;
    
    for (let attempt = 0; attempt <= retryConfig.maxRetries; attempt++) {
      try {
        const result = await operation();
        if (result.success || attempt === retryConfig.maxRetries) {
          return result;
        }
        lastError = result.error;
      } catch (error) {
        lastError = error;
        if (attempt === retryConfig.maxRetries) break;
      }
      
      if (attempt < retryConfig.maxRetries) {
        const delay = exponentialBackoff(attempt);
        console.log(`üîÑ Retry ${attempt + 1}/${retryConfig.maxRetries} pour ${context} dans ${delay}ms`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
    
    return {
      success: false,
      error: `√âchec apr√®s ${retryConfig.maxRetries + 1} tentatives`,
      message: lastError?.message || 'Erreur inconnue'
    };
  };

  const handleError = (response: ProxyS3Response<any>, defaultMessage: string) => {
    const errorMessage = response.error || response.message || defaultMessage;
    setError(errorMessage);
    toast({
      title: "Erreur",
      description: response.message || errorMessage,
      variant: "destructive"
    });
    return false;
  };

  const initialize = useCallback(async (credentials: S3Credentials): Promise<boolean> => {
    setLoading(true);
    setError(null);

    try {
      console.log('üöÄ Initialisation S3 direct avec cache intelligent');
      const response = await withRetry(
        () => proxyS3Service.initialize(credentials),
        'initialisation proxy S3'
      );
      
      if (response.success) {
        setInitialized(true);
        console.log('‚úÖ S3 initialis√© avec succ√®s');
        return true;
      } else {
        return handleError(response, 'Erreur lors de l\'initialisation');
      }
    } catch (error) {
      console.error('‚ùå Initialize error:', error);
      setError('Erreur de connexion');
      return false;
    } finally {
      setLoading(false);
    }
  }, []);

  const fetchBuckets = useCallback(async (forceRefresh: boolean = false): Promise<boolean> => {
    if (!initialized) return false;
    
    if (forceRefresh) {
      cacheService.clearByPattern('buckets_');
    }
    
    setLoading(true);
    setError(null);

    try {
      const response = await withRetry(
        () => proxyS3Service.getBuckets(),
        'r√©cup√©ration buckets'
      );
      
      if (response.success && response.data) {
        setBuckets(response.data);
        return true;
      } else {
        return handleError(response, 'Erreur lors du chargement des buckets');
      }
    } catch (error) {
      console.error('‚ùå Fetch buckets error:', error);
      setError('Erreur de connexion');
      return false;
    } finally {
      setLoading(false);
    }
  }, [initialized]);

  const fetchObjects = useCallback(async (bucket: string, path: string = '', forceRefresh: boolean = false): Promise<boolean> => {
    if (!initialized) return false;
    
    if (forceRefresh) {
      cacheService.clearByPattern(`objects_${bucket}`);
    }
    
    setLoading(true);
    setError(null);

    try {
      const response = await withRetry(
        () => proxyS3Service.getObjects(bucket, path),
        `r√©cup√©ration objects ${bucket}/${path}`
      );
      
      if (response.success && response.data) {
        setObjects(response.data);
        return true;
      } else {
        return handleError(response, 'Erreur lors du chargement des objets');
      }
    } catch (error) {
      console.error('‚ùå Fetch objects error:', error);
      setError('Erreur de connexion');
      return false;
    } finally {
      setLoading(false);
    }
  }, [initialized]);

  // Upload concurrent avec limite de 5 uploads simultan√©s
  const uploadFile = useCallback(async (file: File, bucket: string, path: string = ''): Promise<boolean> => {
    if (!initialized) return false;

    const fileKey = `${bucket}/${path}/${file.name}`;
    
    // Ajouter √† la queue si trop d'uploads actifs
    if (activeUploadsRef.current.size >= 5) {
      uploadQueueRef.current.push(file);
      setUploadProgress(prev => ({
        ...prev,
        [fileKey]: { file: file.name, progress: 0, status: 'pending' }
      }));
      return true;
    }

    activeUploadsRef.current.add(fileKey);
    setUploadProgress(prev => ({
      ...prev,
      [fileKey]: { file: file.name, progress: 0, status: 'uploading' }
    }));

    try {
      // Simuler progression
      const progressInterval = setInterval(() => {
        setUploadProgress(prev => {
          const current = prev[fileKey];
          if (current && current.progress < 90) {
            return {
              ...prev,
              [fileKey]: { ...current, progress: current.progress + 15 }
            };
          }
          return prev;
        });
      }, 150);

      try {
        const response = await withRetry(
          () => proxyS3Service.uploadFile(bucket, path, file),
          `upload ${file.name}`
        );

        clearInterval(progressInterval);

        if (response.success) {
          setUploadProgress(prev => ({
            ...prev,
            [fileKey]: { file: file.name, progress: 100, status: 'completed' }
          }));
          
          toast({
            title: "Succ√®s",
            description: `"${file.name}" upload√© avec succ√®s`
          });
          
          return true;
        } else {
          setUploadProgress(prev => ({
            ...prev,
            [fileKey]: { 
              file: file.name, 
              progress: 0, 
              status: 'error',
              error: response.error || 'Erreur d\'upload' 
            }
          }));
          handleError(response, 'Erreur lors de l\'upload');
          return false;
        }
      } catch (error) {
        clearInterval(progressInterval);
        console.error('‚ùå Upload error:', error);
        setUploadProgress(prev => ({
          ...prev,
          [fileKey]: { 
            file: file.name, 
            progress: 0, 
            status: 'error',
            error: 'Erreur de connexion' 
          }
        }));
        setError('Erreur de connexion');
        return false;
      } finally {
        activeUploadsRef.current.delete(fileKey);
        
        // Traiter la queue
        if (uploadQueueRef.current.length > 0) {
          const nextFile = uploadQueueRef.current.shift();
          if (nextFile) {
            setTimeout(() => uploadFile(nextFile, bucket, path), 100);
          }
        }
        
        // Nettoyer l'√©tat apr√®s 3 secondes
        setTimeout(() => {
          setUploadProgress(prev => {
            const newState = { ...prev };
            delete newState[fileKey];
            return newState;
          });
        }, 3000);
      }
    } catch (outerError) {
      console.error('‚ùå Upload outer error:', outerError);
      activeUploadsRef.current.delete(fileKey);
      return false;
    }
  }, [initialized, toast]);

  const createBucket = useCallback(async (name: string, region: string): Promise<boolean> => {
    if (!initialized) return false;
    
    setLoading(true);
    setError(null);

    // Log operation start
    const logEntryId = s3LoggingService.logOperationStart(
      'bucket_create',
      name,
      undefined,
      `R√©gion: ${region}`
    );

    try {
      const response = await withRetry(
        () => proxyS3Service.createBucket(name),
        `cr√©ation bucket ${name}`
      );
      
      if (response.success) {
        // Log success
        s3LoggingService.logOperationSuccess(
          logEntryId,
          'bucket_create',
          name,
          undefined,
          `Bucket cr√©√© dans la r√©gion ${region}`
        );
        
        // Invalider le cache des buckets et forcer le refresh
        cacheService.delete('buckets');
        await fetchBuckets(true);
        
        toast({
          title: "Succ√®s",
          description: `Bucket "${name}" cr√©√© avec succ√®s`
        });
        return true;
      } else {
        // Log error
        s3LoggingService.logOperationError(
          logEntryId,
          'bucket_create',
          response.error || 'Erreur lors de la cr√©ation',
          name,
          undefined,
          'CREATE_FAILED'
        );
        return handleError(response, 'Erreur lors de la cr√©ation du bucket');
      }
    } catch (error) {
      console.error('‚ùå Create bucket error:', error);
      s3LoggingService.logOperationError(
        logEntryId,
        'bucket_create',
        error instanceof Error ? error : 'Erreur de connexion',
        name,
        undefined,
        'NETWORK_ERROR'
      );
      setError('Erreur de connexion');
      return false;
    } finally {
      setLoading(false);
    }
  }, [initialized, fetchBuckets]);

  const deleteBucket = useCallback(async (name: string, force: boolean = false): Promise<boolean> => {
    if (!initialized) return false;
    
    setLoading(true);
    setError(null);

    // Log operation start
    const logEntryId = s3LoggingService.logOperationStart(
      'bucket_delete',
      name,
      undefined,
      force ? 'Suppression forc√©e (avec vidange)' : undefined
    );

    try {
      const response = await withRetry(
        () => proxyS3Service.deleteBucket(name, force),
        `suppression bucket ${name}`
      );
      
      if (response.success) {
        // Log success
        s3LoggingService.logOperationSuccess(
          logEntryId,
          'bucket_delete',
          name,
          undefined,
          'Bucket supprim√© avec succ√®s'
        );
        
        toast({
          title: "Succ√®s",
          description: `Bucket "${name}" supprim√© avec succ√®s`
        });
        
        // Invalider le cache et forcer le refresh
        cacheService.delete('buckets');
        cacheService.clearByPattern('buckets_');
        await fetchBuckets(true);
        
        return true;
      } else {
        // Log error
        s3LoggingService.logOperationError(
          logEntryId,
          'bucket_delete',
          response.error || 'Erreur lors de la suppression',
          name,
          undefined,
          'DELETE_FAILED'
        );
        return handleError(response, 'Erreur lors de la suppression du bucket');
      }
    } catch (error) {
      console.error('‚ùå Delete bucket error:', error);
      s3LoggingService.logOperationError(
        logEntryId,
        'bucket_delete',
        error instanceof Error ? error : 'Erreur de connexion',
        name,
        undefined,
        'NETWORK_ERROR'
      );
      setError('Erreur de connexion');
      return false;
    } finally {
      setLoading(false);
    }
  }, [initialized, fetchBuckets]);

  const deleteObject = useCallback(async (bucket: string, objectKey: string): Promise<boolean> => {
    if (!initialized) return false;

    // Log operation start
    const logEntryId = s3LoggingService.logOperationStart(
      'object_delete',
      bucket,
      objectKey
    );

    try {
      const response = await withRetry(
        () => proxyS3Service.deleteObject(bucket, objectKey),
        `suppression ${objectKey}`
      );
      
      if (response.success) {
        // Log success
        s3LoggingService.logOperationSuccess(
          logEntryId,
          'object_delete',
          bucket,
          objectKey,
          'Objet supprim√© avec succ√®s'
        );
        
        toast({
          title: "Succ√®s",
          description: `"${objectKey}" supprim√© avec succ√®s`
        });
        return true;
      } else {
        // Log error
        s3LoggingService.logOperationError(
          logEntryId,
          'object_delete',
          response.error || 'Erreur lors de la suppression',
          bucket,
          objectKey,
          'DELETE_FAILED'
        );
        return handleError(response, 'Erreur lors de la suppression');
      }
    } catch (error) {
      console.error('‚ùå Delete object error:', error);
      s3LoggingService.logOperationError(
        logEntryId,
        'object_delete',
        error instanceof Error ? error : 'Erreur de connexion',
        bucket,
        objectKey,
        'NETWORK_ERROR'
      );
      setError('Erreur de connexion');
      return false;
    }
  }, [initialized, toast]);

  const downloadObject = useCallback(async (bucket: string, objectKey: string, fileName?: string): Promise<void> => {
    if (!initialized) return;

    try {
      const response = await withRetry(
        () => proxyS3Service.getDownloadUrl(bucket, objectKey),
        `t√©l√©chargement ${objectKey}`
      );
      
      if (response.success && response.data?.url) {
        // Extraire le nom du fichier depuis la cl√© S3 si non fourni
        const downloadName = fileName || objectKey.split('/').pop() || objectKey;
        
        // Cr√©er un lien temporaire pour forcer le t√©l√©chargement avec le bon nom
        const link = document.createElement('a');
        link.href = response.data.url;
        link.download = downloadName;
        link.target = '_blank';
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
      } else {
        handleError(response, 'Erreur lors de la g√©n√©ration du lien de t√©l√©chargement');
      }
    } catch (error) {
      console.error('‚ùå Download error:', error);
      setError('Erreur de connexion');
    }
  }, [initialized]);

  const createFolder = useCallback(async (bucket: string, path: string, folderName: string): Promise<boolean> => {
    if (!initialized) return false;

    // Log operation start
    const logEntryId = s3LoggingService.logOperationStart(
      'folder_create',
      bucket,
      `${path}${folderName}/`,
      `Dossier dans ${path || 'racine'}`
    );

    try {
      const response = await withRetry(
        () => proxyS3Service.createFolder(bucket, path, folderName),
        `cr√©ation dossier ${folderName}`
      );
      
      if (response.success) {
        // Log success
        s3LoggingService.logOperationSuccess(
          logEntryId,
          'folder_create',
          bucket,
          `${path}${folderName}/`,
          `Dossier cr√©√© dans ${path || 'racine'}`
        );
        
        toast({
          title: "Succ√®s",
          description: `Dossier "${folderName}" cr√©√© avec succ√®s`
        });
        return true;
      } else {
        // Log error
        s3LoggingService.logOperationError(
          logEntryId,
          'folder_create',
          response.error || 'Erreur lors de la cr√©ation',
          bucket,
          `${path}${folderName}/`,
          'CREATE_FAILED'
        );
        return handleError(response, 'Erreur lors de la cr√©ation du dossier');
      }
    } catch (error) {
      console.error('‚ùå Create folder error:', error);
      s3LoggingService.logOperationError(
        logEntryId,
        'folder_create',
        error instanceof Error ? error : 'Erreur de connexion',
        bucket,
        `${path}${folderName}/`,
        'NETWORK_ERROR'
      );
      setError('Erreur de connexion');
      return false;
    }
  }, [initialized, toast]);

  const logout = useCallback((): void => {
    console.log('üö™ D√©connexion et nettoyage du cache');
    setInitialized(false);
    setUploadProgress({});
    uploadQueueRef.current = [];
    activeUploadsRef.current.clear();
    cacheService.clear();
    storeLogout();
  }, [storeLogout]);

  const getCacheStats = useCallback(() => {
    return cacheService.getStats();
  }, []);

  return {
    initialized,
    uploadProgress,
    initialize,
    fetchBuckets,
    createBucket,
    deleteBucket,
    fetchObjects,
    uploadFile,
    deleteObject,
    downloadObject,
    createFolder,
    logout,
    getCacheStats
  };
};